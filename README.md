# ğŸ“„ RAG-Based PDF Chatbot

A **Retrieval-Augmented Generation (RAG)** chatbot that allows users to upload PDF documents and ask questions grounded strictly in the document content.

Built using **OpenAI embeddings**, **FAISS vector search**, and a **Streamlit** interface with **citations, debugging tools, and conversation-aware retrieval**.

---

## ğŸš€ Features

- ğŸ“„ Upload and ingest PDF documents  
- ğŸ” Semantic search using vector embeddings  
- ğŸ’¬ Chat-style UI built with Streamlit  
- ğŸ“Œ Inline citations for every factual answer  
- ğŸ§ª Debug panel to inspect retrieved chunks and similarity scores  
- ğŸ§  Conversation-aware retrieval (chat memory)  
- âš¡ Fast local vector search using FAISS  

---

## ğŸ§  How It Works (RAG Pipeline)

PDF â†’ Text Extraction â†’ Chunking â†’ Embeddings â†’ FAISS Vector Store
â†“
User Query â†’ Embedding â†’ Similarity Search â†’ Context â†’ LLM Answer


### Why RAG?
- Prevents hallucinations  
- Keeps answers grounded in source documents  
- Allows dynamic, up-to-date knowledge without fine-tuning  

---

## ğŸ›  Tech Stack

- **Language:** Python  
- **LLM API:** OpenAI  
- **Embeddings:** `text-embedding-3-small`  
- **Vector Store:** FAISS  
- **UI:** Streamlit  
- **PDF Parsing:** PyPDF  

---

## ğŸ“ Project Structure

rag-pdf-chatbot/
â”‚â”€â”€ app.py # Streamlit application
â”‚â”€â”€ requirements.txt # Dependencies
â”‚â”€â”€ README.md
â”‚â”€â”€ .gitignore
â”‚â”€â”€ data/
â”‚ â””â”€â”€ pdfs/ # (Optional) PDF storage


> âš ï¸ Vector index files (`faiss.index`, `chunks.npy`) are generated at runtime and are not committed.

---

## â–¶ï¸ Running the Project Locally

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/jvnganesh/rag-pdf-chatbot.git
cd rag-pdf-chatbot
2ï¸âƒ£ Install dependencies
pip install -r requirements.txt
3ï¸âƒ£ Set OpenAI API Key
Linux / macOS

export OPENAI_API_KEY="your_api_key_here"
Windows (PowerShell)

setx OPENAI_API_KEY "your_api_key_here"
Restart the terminal after setting the key.

4ï¸âƒ£ Run the application
streamlit run app.py
ğŸ“„ Usage Instructions
Upload one or more text-based PDFs

Click â€œProcess PDFsâ€ to ingest documents

Ask questions related to the uploaded content

View answers with inline citations

Enable Debug Panel to inspect retrieved chunks

ğŸ§ª Debug Panel
The debug panel shows:

Retrieved document chunks

Similarity distances

Context used by the LLM

This helps with:

Understanding retrieval behavior

Debugging hallucinations

Improving chunking and retrieval strategies

âš ï¸ Limitations
Scanned PDFs are not supported (OCR not included)

Vector index is rebuilt on each ingestion

Designed for local / demo usage (not production-scale yet)

ğŸ“Œ Future Improvements
Reranking for higher retrieval accuracy

Evaluation metrics for RAG performance

OCR support for scanned PDFs

Production deployment using FastAPI

Persistent vector storage

ğŸ“œ License
MIT License

ğŸ‘¤ Author
JVN Ganesh
GitHub: https://github.com/jvnganesh
